{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "(25/11/2020 - 09/12/2020)\n",
    "***\n",
    "\n",
    "### **Status/Progress Report:**\n",
    "\n",
    "##### **[ Status ] | Time Spent (minutes) | Implementation/ Documentation Tasks**\n",
    "\n",
    "- [x] | [  120 minutes ] | **Generative Models Concepts and Documentation**\n",
    "- [ ] | [  __ minutes ] | Candidate Models for Image generation ( Pros/ Cons ) \n",
    "- [ ] | [  __ minutes ] | \n",
    "- [ ] | [  __ minutes ] | \n",
    "- [ ] | [  __ minutes ] | \n",
    "- [ ] | [  __ minutes ] | \n",
    "- [ ] | [  __ minutes ] | \n",
    "- [ ] | [  __ minutes ] | \n",
    "- [ ] | [  __ minutes ] | \n",
    "- [ ] | [  __ minutes ] | \n",
    "- [ ] | [  __ minutes ] | \n",
    "- [ ] | [  __ minutes ] |\n",
    "\n",
    "Total Time (Hours) : \n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Image Generation( Sythesis ) with Generative Models.\n",
    "\n",
    "Image Generation is the task of genetating new image | given existing images.\n",
    "- Generating image unconditionally from dataset. i.e. $y$ is termed as **Unconditional image generation**. whereas generating samples conditionally( Subtask ), based on labels i.e. $p(y|x)$, as **Conditional image generation**.\n",
    "\n",
    "\n",
    "## Generative Models. \n",
    "\n",
    "- **Generative modeling** tries to form the representation of probability distribution(i.e. Density Estimation), which explains( | represents) collection of input training examples. \n",
    "- Generetive Adversarial Network generate new samples from generator network given the collection of inputs without estimating Density functions improving with adversarial discriminator network supervising the generated samples.\n",
    "\n",
    "**Maximum Likelihood**\n",
    "\n",
    "- $x$ is the vector describing the input.\n",
    "- $p_{model}(x)$ is the density function that the model describes. \n",
    "- $p_{model}(x | \\theta)$ is the distibution controlled by parameter$\\theta$, which describes the concentratration/spread of the data.\n",
    "- Performing maximum likelihood consists of measuring the log probability that ($p_{model}(x)$) assigns to each input ($x$) data points and adjusting the paramter $\\theta$ to increase that probability.\n",
    "\n",
    "\n",
    "$$\n",
    "    \\boxed{\\theta^* = arg_\\theta max\\mathbb{E}_{x\\sim p_{data}}\\log p_{model}(x | \\theta )}\n",
    "$$\n",
    "\n",
    "\n",
    "Generative Modeling based on Performing Maximum Likelihood: [[Reference 1.]](https://arxiv.org/pdf/1701.00160.pdf)\n",
    "\n",
    "![](../generative.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network\n",
    " \n",
    "- **Generative Adversarial Network(GAN)** is composed of : a generator(G) & a discriminator (D). It is used to generate new samples from learned latent space.\n",
    "\n",
    "![](gan.png)\n",
    "[[@imgsource]](https://www.kdnuggets.com/wp-content/uploads/generative-adversarial-network.png)\n",
    "\n",
    "**Generative vs Discriminative models**\n",
    "- Generative models capture the joint probability $p(X, Y)$, or just $p(X)$ if there are no labels.\n",
    "- Discriminative models capture the conditional probability $p(Y | X)$\n",
    "-Discriminative models try to draw boundaries in the data space, while generative models try to model how data is placed throughout the space.\n",
    "\n",
    "The generator output is connected directly to the discriminator input. Through backpropagation, the discriminator's classification provides a signal that the generator uses to update its weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN-MNIST dataset ( PyTorch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as datasets\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 30\n",
    "batch_size = 32\n",
    "sample_dir = 'samples'\n",
    "save_dir = 'save'\n",
    "g\n",
    "# Create a directory if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing\n",
    "transform = transforms.Compose([\n",
    "transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = torchvision.datasets.MNIST(root='./data/*'\n",
    "                                   , train=True\n",
    "                                   , download=True\n",
    "                                   , transform = transforms.Compose([\n",
    "                                       transforms.ToTensor()\n",
    "                                       , transforms.Normalize([0.5], [0.5])]))\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist\n",
    "                                          , batch_size=batch_size \n",
    "                                          , shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "\n",
    "- It tries to generate fake data from randomly generated noise G(z), which are harder to discriminate each iteration, from real ones.\n",
    "\n",
    "- It learns to generate plausible data. The generated instances become negative training examples for the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    def __init__(self):\n",
    "        self.main = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(latent_size, hidden_size)\n",
    "            , nn.ReLU()\n",
    "            , nn.Linear(hidden_size, hidden_size)\n",
    "            , nn.ReLU()\n",
    "            , nn.Linear(hidden_size, image_size)\n",
    "            , nn.Tanh()\n",
    "        )\n",
    "        \n",
    "G = Generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "\n",
    "- It learns to distinguish the generator's fake data from real data. The discriminator penalizes the generator for producing implausible results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator():\n",
    "    def __init__(self):\n",
    "        self.main = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(image_size, hidden_size)\n",
    "            , nn.LeakyReLU(0.2)\n",
    "            , nn.Linear(hidden_size, hidden_size)\n",
    "            , nn.LeakyReLU(0.2)\n",
    "            , nn.Linear(hidden_size, 1)\n",
    "            , nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "D = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(image_size, hidden_size)\n",
    "    , nn.LeakyReLU(0.2)\n",
    "    , nn.Linear(hidden_size, hidden_size)\n",
    "    , nn.LeakyReLU(0.2)\n",
    "    , nn.Linear(hidden_size, 1)\n",
    "    , nn.Sigmoid())\n",
    "\n",
    "# Generator \n",
    "G = nn.Sequential(\n",
    "    nn.Linear(latent_size, hidden_size)\n",
    "    , nn.ReLU()\n",
    "    , nn.Linear(hidden_size, hidden_size)\n",
    "    , nn.ReLU()\n",
    "    , nn.Linear(hidden_size, image_size)\n",
    "    , nn.Tanh())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MiniMax Game | *Adversarial Learning*\n",
    "- After training, D & G will reach saturation of improvement.\n",
    "- Gererator(G) wins (i.e. learns to create realistic data ) when Discriminator(D) can't differentiate generated data from the real one.\n",
    "- This loss function maximizes the function $D(x)$, and also minimizes $D(G(z))$. where 'x': real data, 'G(z)': generrated data. \n",
    "\n",
    "$$\n",
    "    \\boxed{\\min_G \\max_D V(D, G)= \\mathbb{E}_{x\\sim p_{data}(x)}[\\log D(x)] + \\mathbb{E}_{z\\sim p_z(z)}[\\log(1 - D(G(z)))]} \n",
    "$$\n",
    "\n",
    "**Generator :**\n",
    "\n",
    "$\\because x$ is the actual image, $D(x) = 1$ ,  generator tries to increase the value of $D(G(z))$ (i.e. Probability of being real data )\n",
    "- Training G : Maximizing the probability of $D$ making mistakes by generating data as realistic as possible.\n",
    "\n",
    "**Discriminator :**\n",
    "\n",
    "$\\because x$ is the actual image, $D(x) = 1$, discriminator tries to decrease the value of $D(G(z))$ towards 0 (i.e. fake data )\n",
    "\n",
    "### Binary Cross Entropy Loss( `BCE-Loss` ):\n",
    "\n",
    "- v : inputs, w: weights, y : targets, N : batch size\n",
    "\n",
    "$$\n",
    "    \\boxed{L = {\\{l_1, ... , l_N\\}}^T, l_i = -w_i\\left[ y_i \\cdot \\log(v_i) + (1-y)\\cdot \\log(1-v_i)\\right]}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary cross entropy loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\n",
    "\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "def reset_grad():\n",
    "    d_optimizer.zero_grad()\n",
    "    g_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Loss:\n",
    "\n",
    "$$\n",
    "    \\boxed{D_{o}=\\frac{1}{m} \\sum_{i=1}^{m}\\left[ \\log D(x^{(i)}) + \\log (1-D(G(z^{(i)}))) \\right]} \n",
    "$$\n",
    "\n",
    "1. If $v_i = D(x_i)$ and $y_i=1 \\forall i$ in the `BCE-Loss above ⬆️` : Loss related to real images.\n",
    "2. If $v_i = D(G(x))$ and $y_i=0 \\forall i$ : Loss related to fake images.\n",
    "3. Sum of `1` and `2` : **`minibatch-loss`** for the Discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Loss:\n",
    "\n",
    "$$\n",
    "    \\boxed{G_{o}=\\frac{1}{m} \\sum_{i=1}^{m}\\log \\left({1 - D\\left(G\\left(z^{(i)}\\right)\\right)}\\right)} \n",
    "$$\n",
    "\n",
    "- If $v_i = D(G(z_i))$ and $y_i = 1 \\forall i$ : Loss needed to be minimized.\n",
    "- Train the generator to maximize $\\log \\left(D(G(z)))\\right)$ ( provides stronger gradients early in training [Ref.@Section3](https://arxiv.org/pdf/1406.2661.pdf)) rather than minimizing $\\log \\left( 1- D(G(z))\\right)$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/30], Step [200/1875], d_loss: 0.0444, g_loss: 4.0551, D(x): 0.99, D(G(z)): 0.04\n",
      "Epoch [0/30], Step [400/1875], d_loss: 0.0804, g_loss: 6.1258, D(x): 0.96, D(G(z)): 0.03\n",
      "Epoch [0/30], Step [600/1875], d_loss: 0.0267, g_loss: 5.5235, D(x): 0.99, D(G(z)): 0.02\n",
      "Epoch [0/30], Step [800/1875], d_loss: 0.0898, g_loss: 5.2586, D(x): 0.96, D(G(z)): 0.02\n"
     ]
    }
   ],
   "source": [
    "# Statistics to be saved\n",
    "d_losses = np.zeros(num_epochs)\n",
    "g_losses = np.zeros(num_epochs)\n",
    "real_scores = np.zeros(num_epochs)\n",
    "fake_scores = np.zeros(num_epochs)\n",
    "\n",
    "total_step = len(data_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        images = images.view(batch_size, -1)\n",
    "        images = Variable(images)\n",
    "        # Create the labels which are later used as input for the BCE loss\n",
    "        real_labels = torch.ones(batch_size, 1)\n",
    "        real_labels = Variable(real_labels)\n",
    "        fake_labels = torch.zeros(batch_size, 1)\n",
    "        fake_labels = Variable(fake_labels)\n",
    "\n",
    "        # ================================================================== #\n",
    "        #                      Train the discriminator                       #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
    "        # Second term of the loss is always zero since real_labels == 1\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        # Compute BCELoss using fake images\n",
    "        # First term of the loss is always zero since fake_labels == 0\n",
    "        z = torch.randn(batch_size, latent_size)\n",
    "        z = Variable(z)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        # If D is trained so well, then don't update\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        reset_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        # ================================================================== #\n",
    "        #                        Train the generator                         #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # Compute loss with fake images\n",
    "        z = torch.randn(batch_size, latent_size)\n",
    "        z = Variable(z)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        \n",
    "        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
    "        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        # if G is trained so well, then don't update\n",
    "        reset_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        # =================================================================== #\n",
    "        #                          Update Statistics                          #\n",
    "        # =================================================================== #\n",
    "        d_losses[epoch] = d_losses[epoch]*(i/(i+1.)) + d_loss.data*(1./(i+1.))\n",
    "        g_losses[epoch] = g_losses[epoch]*(i/(i+1.)) + g_loss.data*(1./(i+1.))\n",
    "        real_scores[epoch] = real_scores[epoch]*(i/(i+1.)) + real_score.mean().data*(1./(i+1.))\n",
    "        fake_scores[epoch] = fake_scores[epoch]*(i/(i+1.)) + fake_score.mean().data*(1./(i+1.))\n",
    "        \n",
    "        if (i+1) % 200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch, num_epochs, i+1, total_step, d_loss.data, g_loss.data, \n",
    "                          real_score.mean().data, fake_score.mean().data))\n",
    "    \n",
    "    # Save real images\n",
    "    if (epoch+1) == 1:\n",
    "        images = images.view(images.size(0), 1, 28, 28)\n",
    "        save_image(denorm(images.data), os.path.join(sample_dir, 'real_images.png'))\n",
    "    \n",
    "    # Save sampled images\n",
    "    fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n",
    "    save_image(denorm(fake_images.data), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n",
    "    \n",
    "    # Save and plot Statistics\n",
    "    np.save(os.path.join(save_dir, 'd_losses.npy'), d_losses)\n",
    "    np.save(os.path.join(save_dir, 'g_losses.npy'), g_losses)\n",
    "    np.save(os.path.join(save_dir, 'fake_scores.npy'), fake_scores)\n",
    "    np.save(os.path.join(save_dir, 'real_scores.npy'), real_scores)\n",
    "    \n",
    "    plt.figure()\n",
    "    pylab.xlim(0, num_epochs + 1)\n",
    "    plt.plot(range(1, num_epochs + 1), d_losses, label='d loss')\n",
    "    plt.plot(range(1, num_epochs + 1), g_losses, label='g loss')    \n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'loss.pdf'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    pylab.xlim(0, num_epochs + 1)\n",
    "    pylab.ylim(0, 1)\n",
    "    plt.plot(range(1, num_epochs + 1), fake_scores, label='fake score')\n",
    "    plt.plot(range(1, num_epochs + 1), real_scores, label='real score')    \n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'accuracy.pdf'))\n",
    "    plt.close()\n",
    "\n",
    "    # Save model at checkpoints\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        torch.save(G.state_dict(), os.path.join(save_dir, 'G--{}.ckpt'.format(epoch+1)))\n",
    "        torch.save(D.state_dict(), os.path.join(save_dir, 'D--{}.ckpt'.format(epoch+1)))\n",
    "\n",
    "# Save the model checkpoints \n",
    "torch.save(G.state_dict(), 'G.ckpt')\n",
    "torch.save(D.state_dict(), 'D.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Samples\n",
    "\n",
    "#### Epoch 1. (Random noise)\n",
    "\n",
    "![](./samples/fake_images-1.png)\n",
    "\n",
    ". </br>\n",
    "[.](https://aihubprojects.com/gan-implementation-on-mnist-dataset-pytorch/) </br>\n",
    ". </br>\n",
    "\n",
    "#### Epoch 300. \n",
    "\n",
    "![](./samples/fake_images-300.png)\n",
    "\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referenced Candidates\n",
    "\n",
    "\n",
    "- Generative Adversarial Networks\n",
    "    - [Self Attention GAN](https://github.com/heykeetae/Self-Attention-GAN)\n",
    "    - [StyleGAN2](https://github.com/lucidrains/stylegan2-pytorch)\n",
    "- [Denoising Diffusion Probabilistic models](https://github.com/lucidrains/denoising-diffusion-pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
