{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Exploration of Deep Generative models on Art Generation Domain\n",
    "***\n",
    "**>>> Biweekly Report 1.** ( $25^{th} Nov - 9^{th} Dec : 2020$ )\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "**Contents**\n",
    "\n",
    "1. Implementation Status/ Progress\n",
    "2. Observations\n",
    "    - MNIST Dataset\n",
    "    - Art Dataset\n",
    "3. Conclusion\n",
    "    - Criterias, Drawbacks, and Possible Solutions ( Insight next iteration )\n",
    "4. Image Generation with Generative models ( Exploration )\n",
    "    - Generative Models\n",
    "    - Generative Adversarial Learning\n",
    "5. Multilayer Perceptron GAN Implementation using Pytorch\n",
    "    - MNIST Dataset ( Ref: `gan.py` or `VanillaGAN.ipynb` )\n",
    "    - Art Dataset ( Ref: `ganArt.py`)\n",
    "6. Candidate Papers/ Deep Learning Models Applicable to Art Generation Domain.\n",
    "\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "# 1. Implementation Status/ Progress\n",
    "\n",
    "##### **[ Status ] | Time Spent (~Hours) | Implementation/ Documentation Tasks**\n",
    "\n",
    "\n",
    "- [x] | [  2.5  ] | **Generative Models Concepts and Documentation**\n",
    "- [ ] | [  __ ] | Candidate Models for Image generation ( Pros/ Cons ) \n",
    "- [ ] | [  __ ] | \n",
    "- [ ] | [  __ ] | \n",
    "- [ ] | [  __ ] | \n",
    "- [ ] | [  __ ] | \n",
    "- [ ] | [  __ ] | \n",
    "\n",
    "\n",
    "Total Time (Hours) : \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Observations\n",
    "\n",
    "### Generated Samples ( MNIST Dataset )\n",
    "\n",
    "\n",
    "#### Hyperparameters\n",
    "\n",
    "```\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "```\n",
    "\n",
    "##### Epoch 1. (Random noise)\n",
    "\n",
    "![](./sample-Epoch1.png)\n",
    "\n",
    ". </br>\n",
    "[.](https://aihubprojects.com/gan-implementation-on-mnist-dataset-pytorch/) </br>\n",
    ". </br>\n",
    "\n",
    "##### Epoch 10. ( simple representation )\n",
    "\n",
    "![](./sample-Epoch10.png)\n",
    "\n",
    "##### Epoch 50. ( Almost realistic )\n",
    "\n",
    "![](./sample-Epoch49.png)\n",
    "\n",
    "***\n",
    "\n",
    "### Generated Samples (ART Dataset )\n",
    "\n",
    "```\n",
    "latent_size = 256\n",
    "hidden_size = 64\n",
    "image_size = 49152\n",
    "num_epochs = 50\n",
    "batch_size = 4\n",
    "```\n",
    "\n",
    "##### Epoch 1. (Random RGB noise )\n",
    "\n",
    "![](./fake_art-1.png)\n",
    "\n",
    "##### Epoch 10.\n",
    "\n",
    "![](./fake_art-10.png)\n",
    "\n",
    "##### Epoch 50\n",
    "\n",
    "![](./fake_art-49.png)\n",
    "\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Conclusion\n",
    "\n",
    "After Gathering \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Image Generation( Sythesis ) with Generative Models.\n",
    "\n",
    "Image Generation is the task of genetating new image | given existing images.\n",
    "- Generating image unconditionally from dataset. i.e. $y$ is termed as **Unconditional image generation**. whereas generating samples conditionally( Subtask ), based on labels i.e. $p(y|x)$, as **Conditional image generation**.\n",
    "\n",
    "\n",
    "## Generative Models. \n",
    "\n",
    "- **Generative modeling** tries to form the representation of probability distribution(i.e. Density Estimation), which explains( | represents) collection of input training examples. \n",
    "- Generetive Adversarial Network generate new samples from generator network given the collection of inputs without estimating Density functions improving with adversarial discriminator network supervising the generated samples.\n",
    "\n",
    "**Maximum Likelihood**\n",
    "\n",
    "- $x$ is the vector describing the input.\n",
    "- $p_{model}(x)$ is the density function that the model describes. \n",
    "- $p_{model}(x | \\theta)$ is the distibution controlled by parameter$\\theta$, which describes the concentratration/spread of the data.\n",
    "- Performing maximum likelihood consists of measuring the log probability that ($p_{model}(x)$) assigns to each input ($x$) data points and adjusting the paramter $\\theta$ to increase that probability.\n",
    "\n",
    "\n",
    "$$\n",
    "    \\boxed{\\theta^* = arg_\\theta max\\mathbb{E}_{x\\sim p_{data}}\\log p_{model}(x | \\theta )}\n",
    "$$\n",
    "\n",
    "\n",
    "Generative Modeling based on Performing Maximum Likelihood: [[Reference 1.](https://arxiv.org/pdf/1701.00160.pdf)\n",
    "\n",
    "![](../../../Images/generative.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network\n",
    " \n",
    "- **Generative Adversarial Network(GAN)** [[Reference 2.]](https://arxiv.org/pdf/1406.2661.pdf) is composed of : a generator(G) & a discriminator (D). It is used to generate new samples from learned latent space.\n",
    "\n",
    "![](../../../Images/gan.png)\n",
    "[[@imgsource]](https://www.kdnuggets.com/wp-content/uploads/generative-adversarial-network.png)\n",
    "\n",
    "**Generative vs Discriminative models**\n",
    "- Generative models capture the joint probability $p(X, Y)$, or just $p(X)$ if there are no labels.\n",
    "- Discriminative models capture the conditional probability $p(Y | X)$\n",
    "-Discriminative models try to draw boundaries in the data space, while generative models try to model how data is placed throughout the space.\n",
    "\n",
    "The generator output is connected directly to the discriminator input. Through backpropagation, the discriminator's classification provides a signal that the generator uses to update its weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# 5. Multilayer Perceptron GAN Implementation ( PyTorch )\n",
    "\n",
    "\n",
    "### Datasets :\n",
    "\n",
    "1. MNIST Handwritten digits : Downloaded from Torch Datasets\n",
    "2. Art Dataset : \n",
    "    - ( `./data/1/< images here >` ) `|` create if !exists already\n",
    "    - ( `/1/` due to recursive reading from Dataloader - Pytorch )\n",
    "\n",
    "*Note:* Given Datasets reside in their own directory containing `gan.py | ganArt`.\n",
    "\n",
    "### Instruction :\n",
    "\n",
    "**Jupyter-notebook | Open in Colab**\n",
    "\n",
    "```\n",
    "< Run `jupyter-lab` | Upload to googleColabFolder >\n",
    "\n",
    "< Navigate to VanillaGAN.ipynb >\n",
    "```\n",
    "\n",
    "**Python Interpreter**\n",
    "\n",
    "```python\n",
    "python gan.py |OR| python ganArt.py\n",
    "```\n",
    "\n",
    "***\n",
    "\n",
    "### Import Libs/ Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as datasets\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "sample_dir = 'samples'\n",
    "save_dir = 'save'\n",
    "\n",
    "# Create a directory if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing and Pytorch Dataloader ( Load MNIST )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/*/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d476758e03664e2e9facc19f94099975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/*/MNIST/raw/train-images-idx3-ubyte.gz to ./data/*/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/*/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e023ae0b65fd4e4fbce2db498094e7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/*/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/*/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/*/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61ace5fa1e6480fbb654eec56d226f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/*/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/*/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/*/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f6657cd3004ff3ba2eeb3ffb1f6b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/*/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/*/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mnpr_term/miniconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729062494/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist = torchvision.datasets.MNIST(root='./data/*'\n",
    "                                   , train=True\n",
    "                                   , download=True\n",
    "                                   , transform = transforms.Compose([\n",
    "                                       transforms.ToTensor()\n",
    "                                       , transforms.Normalize([0.5], [0.5])]))\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist\n",
    "                                          , batch_size=batch_size \n",
    "                                          , shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "\n",
    "- It tries to generate fake data from randomly generated noise G(z), which are harder to discriminate each iteration, from real ones.\n",
    "\n",
    "- It learns to generate plausible data. The generated instances become negative training examples for the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class Generator():\n",
    "    def __init__(self):\n",
    "        self.main = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(latent_size, hidden_size)\n",
    "            , nn.ReLU()\n",
    "            , nn.Linear(hidden_size, hidden_size)\n",
    "            , nn.ReLU()\n",
    "            , nn.Linear(hidden_size, image_size)\n",
    "            , nn.Tanh()\n",
    "        )\n",
    "        \n",
    "G = Generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "\n",
    "- It learns to distinguish the generator's fake data from real data. The discriminator penalizes the generator for producing implausible results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator():\n",
    "    def __init__(self):\n",
    "        self.main = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(image_size, hidden_size)\n",
    "            , nn.LeakyReLU(0.2)\n",
    "            , nn.Linear(hidden_size, hidden_size)\n",
    "            , nn.LeakyReLU(0.2)\n",
    "            , nn.Linear(hidden_size, 1)\n",
    "            , nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "D = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optional : W/O using class ( for simplicity now )\n",
    "\n",
    "\n",
    "# Discriminator\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(image_size, hidden_size)\n",
    "    , nn.LeakyReLU(0.2)\n",
    "    , nn.Linear(hidden_size, hidden_size)\n",
    "    , nn.LeakyReLU(0.2)\n",
    "    , nn.Linear(hidden_size, 1)\n",
    "    , nn.Sigmoid())\n",
    "\n",
    "# Generator \n",
    "G = nn.Sequential(\n",
    "    nn.Linear(latent_size, hidden_size)\n",
    "    , nn.ReLU()\n",
    "    , nn.Linear(hidden_size, hidden_size)\n",
    "    , nn.ReLU()\n",
    "    , nn.Linear(hidden_size, image_size)\n",
    "    , nn.Tanh())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MiniMax Game | *Adversarial Learning*\n",
    "- After training, D & G will reach saturation of improvement.\n",
    "- Gererator(G) wins (i.e. learns to create realistic data ) when Discriminator(D) can't differentiate generated data from the real one.\n",
    "- The loss function below maximizes the function $D(x)$, and also minimizes $D(G(z))$. where 'x': real data, 'G(z)': generrated data. \n",
    "\n",
    "$$\n",
    "    \\boxed{\\min_G \\max_D V(D, G)= \\mathbb{E}_{x\\sim p_{data}(x)}[\\log D(x)] + \\mathbb{E}_{z\\sim p_z(z)}[\\log(1 - D(G(z)))]} \n",
    "$$\n",
    "\n",
    "**Generator :**\n",
    "\n",
    "$\\because x$ is the actual image, $D(x) = 1$ ,  generator tries to increase the value of $D(G(z))$ (i.e. Probability of being real data )\n",
    "- Training G : Maximizing the probability of $D$ making mistakes by generating data as realistic as possible.\n",
    "\n",
    "**Discriminator :**\n",
    "\n",
    "$\\because x$ is the actual image, $D(x) = 1$, discriminator tries to decrease the value of $D(G(z))$ towards 0 (i.e. fake data )\n",
    "\n",
    "### Binary Cross Entropy Loss( `BCE-Loss` ):\n",
    "\n",
    "- v : inputs, w: weights, y : targets, N : batch size\n",
    "\n",
    "$$\n",
    "    \\boxed{L = {\\{l_1, ... , l_N\\}}^T, l_i = -w_i\\left[ y_i \\cdot \\log(v_i) + (1-y)\\cdot \\log(1-v_i)\\right]}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary cross entropy loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\n",
    "\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "def reset_grad():\n",
    "    d_optimizer.zero_grad()\n",
    "    g_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Loss:\n",
    "\n",
    "$$\n",
    "    \\boxed{D_{o}=\\frac{1}{m} \\sum_{i=1}^{m}\\left[ \\log D(x^{(i)}) + \\log (1-D(G(z^{(i)}))) \\right]} \n",
    "$$\n",
    "\n",
    "1. If $v_i = D(x_i)$ and $y_i=1 \\forall i$ in the `BCE-Loss above ⬆️` : Loss related to real images.\n",
    "2. If $v_i = D(G(x))$ and $y_i=0 \\forall i$ : Loss related to fake images.\n",
    "3. Sum of `1` and `2` : **`minibatch-loss`** for the Discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Loss:\n",
    "\n",
    "$$\n",
    "    \\boxed{G_{o}=\\frac{1}{m} \\sum_{i=1}^{m}\\log \\left({1 - D\\left(G\\left(z^{(i)}\\right)\\right)}\\right)} \n",
    "$$\n",
    "\n",
    "- If $v_i = D(G(z_i))$ and $y_i = 1 \\forall i$ : Loss needed to be minimized.\n",
    "- Train the generator to maximize $\\log \\left(D(G(z)))\\right)$ ( provides stronger gradients early in training [Reference 1.[]](https://arxiv.org/pdf/1406.2661.pdf)) rather than minimizing $\\log \\left( 1- D(G(z))\\right)$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/5], Step [200/1875], d_loss: 0.0350, g_loss: 4.3827, D(x): 0.99, D(G(z)): 0.03\n",
      "Epoch [0/5], Step [400/1875], d_loss: 0.0607, g_loss: 5.5679, D(x): 1.00, D(G(z)): 0.05\n",
      "Epoch [0/5], Step [600/1875], d_loss: 0.0209, g_loss: 5.2541, D(x): 0.99, D(G(z)): 0.01\n",
      "Epoch [0/5], Step [800/1875], d_loss: 0.0274, g_loss: 6.1005, D(x): 1.00, D(G(z)): 0.02\n",
      "Epoch [0/5], Step [1000/1875], d_loss: 0.0513, g_loss: 4.9315, D(x): 0.99, D(G(z)): 0.04\n",
      "Epoch [0/5], Step [1200/1875], d_loss: 0.3851, g_loss: 3.0876, D(x): 0.84, D(G(z)): 0.05\n",
      "Epoch [0/5], Step [1400/1875], d_loss: 0.1668, g_loss: 4.5172, D(x): 0.90, D(G(z)): 0.03\n",
      "Epoch [0/5], Step [1600/1875], d_loss: 0.0688, g_loss: 3.7536, D(x): 1.00, D(G(z)): 0.06\n",
      "Epoch [0/5], Step [1800/1875], d_loss: 0.3249, g_loss: 2.8770, D(x): 0.91, D(G(z)): 0.18\n",
      "Epoch [1/5], Step [200/1875], d_loss: 0.3954, g_loss: 2.9945, D(x): 0.85, D(G(z)): 0.11\n",
      "Epoch [1/5], Step [400/1875], d_loss: 0.3061, g_loss: 3.9037, D(x): 0.85, D(G(z)): 0.05\n",
      "Epoch [1/5], Step [600/1875], d_loss: 0.5454, g_loss: 3.4739, D(x): 0.77, D(G(z)): 0.02\n",
      "Epoch [1/5], Step [800/1875], d_loss: 0.2721, g_loss: 3.8075, D(x): 0.96, D(G(z)): 0.17\n",
      "Epoch [1/5], Step [1000/1875], d_loss: 0.1008, g_loss: 3.1315, D(x): 0.96, D(G(z)): 0.05\n",
      "Epoch [1/5], Step [1200/1875], d_loss: 0.5635, g_loss: 2.1231, D(x): 0.92, D(G(z)): 0.29\n",
      "Epoch [1/5], Step [1400/1875], d_loss: 0.1120, g_loss: 4.2163, D(x): 0.97, D(G(z)): 0.06\n",
      "Epoch [1/5], Step [1600/1875], d_loss: 0.0131, g_loss: 5.8856, D(x): 1.00, D(G(z)): 0.01\n",
      "Epoch [1/5], Step [1800/1875], d_loss: 0.0888, g_loss: 5.2458, D(x): 0.98, D(G(z)): 0.04\n",
      "Epoch [2/5], Step [200/1875], d_loss: 0.0195, g_loss: 12.9299, D(x): 0.98, D(G(z)): 0.00\n",
      "Epoch [2/5], Step [400/1875], d_loss: 0.0622, g_loss: 7.4073, D(x): 0.98, D(G(z)): 0.04\n",
      "Epoch [2/5], Step [600/1875], d_loss: 0.0747, g_loss: 5.7878, D(x): 0.97, D(G(z)): 0.03\n",
      "Epoch [2/5], Step [800/1875], d_loss: 0.0783, g_loss: 4.1457, D(x): 0.97, D(G(z)): 0.03\n",
      "Epoch [2/5], Step [1000/1875], d_loss: 0.0889, g_loss: 5.6029, D(x): 0.94, D(G(z)): 0.01\n",
      "Epoch [2/5], Step [1200/1875], d_loss: 0.0802, g_loss: 5.3573, D(x): 1.00, D(G(z)): 0.07\n",
      "Epoch [2/5], Step [1400/1875], d_loss: 0.1456, g_loss: 5.4689, D(x): 0.95, D(G(z)): 0.05\n",
      "Epoch [2/5], Step [1600/1875], d_loss: 0.1882, g_loss: 5.1395, D(x): 0.96, D(G(z)): 0.05\n",
      "Epoch [2/5], Step [1800/1875], d_loss: 0.2801, g_loss: 2.4618, D(x): 0.94, D(G(z)): 0.04\n",
      "Epoch [3/5], Step [200/1875], d_loss: 0.2285, g_loss: 3.3289, D(x): 1.00, D(G(z)): 0.19\n",
      "Epoch [3/5], Step [400/1875], d_loss: 0.1459, g_loss: 6.9836, D(x): 0.93, D(G(z)): 0.01\n",
      "Epoch [3/5], Step [600/1875], d_loss: 0.3478, g_loss: 6.6529, D(x): 0.87, D(G(z)): 0.00\n",
      "Epoch [3/5], Step [800/1875], d_loss: 0.6420, g_loss: 3.7981, D(x): 0.85, D(G(z)): 0.22\n",
      "Epoch [3/5], Step [1000/1875], d_loss: 0.5202, g_loss: 3.5789, D(x): 0.88, D(G(z)): 0.19\n",
      "Epoch [3/5], Step [1200/1875], d_loss: 0.0385, g_loss: 5.8691, D(x): 0.99, D(G(z)): 0.03\n",
      "Epoch [3/5], Step [1400/1875], d_loss: 0.2265, g_loss: 4.6683, D(x): 0.92, D(G(z)): 0.04\n",
      "Epoch [3/5], Step [1600/1875], d_loss: 0.4936, g_loss: 5.5454, D(x): 0.85, D(G(z)): 0.02\n",
      "Epoch [3/5], Step [1800/1875], d_loss: 0.1079, g_loss: 3.7956, D(x): 0.95, D(G(z)): 0.05\n",
      "Epoch [4/5], Step [200/1875], d_loss: 0.3118, g_loss: 5.1066, D(x): 0.89, D(G(z)): 0.01\n",
      "Epoch [4/5], Step [400/1875], d_loss: 0.3463, g_loss: 4.6199, D(x): 0.89, D(G(z)): 0.03\n",
      "Epoch [4/5], Step [600/1875], d_loss: 0.1376, g_loss: 3.8951, D(x): 0.96, D(G(z)): 0.05\n",
      "Epoch [4/5], Step [800/1875], d_loss: 0.1128, g_loss: 5.6068, D(x): 0.95, D(G(z)): 0.01\n",
      "Epoch [4/5], Step [1000/1875], d_loss: 0.4015, g_loss: 4.6994, D(x): 0.93, D(G(z)): 0.11\n",
      "Epoch [4/5], Step [1200/1875], d_loss: 0.1114, g_loss: 5.8184, D(x): 0.98, D(G(z)): 0.07\n",
      "Epoch [4/5], Step [1400/1875], d_loss: 0.1387, g_loss: 4.7464, D(x): 0.96, D(G(z)): 0.05\n",
      "Epoch [4/5], Step [1600/1875], d_loss: 0.1481, g_loss: 3.9828, D(x): 0.97, D(G(z)): 0.09\n",
      "Epoch [4/5], Step [1800/1875], d_loss: 0.4006, g_loss: 4.1588, D(x): 0.92, D(G(z)): 0.14\n"
     ]
    }
   ],
   "source": [
    "# Statistics to be saved\n",
    "d_losses = np.zeros(num_epochs)\n",
    "g_losses = np.zeros(num_epochs)\n",
    "real_scores = np.zeros(num_epochs)\n",
    "fake_scores = np.zeros(num_epochs)\n",
    "\n",
    "total_step = len(data_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        images = images.view(batch_size, -1)\n",
    "        images = Variable(images)\n",
    "        # Create the labels which are later used as input for the BCE loss\n",
    "        real_labels = torch.ones(batch_size, 1)\n",
    "        real_labels = Variable(real_labels)\n",
    "        fake_labels = torch.zeros(batch_size, 1)\n",
    "        fake_labels = Variable(fake_labels)\n",
    "\n",
    "        # ================================================================== #\n",
    "        #                      Train the discriminator                       #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
    "        # Second term of the loss is always zero since real_labels == 1\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        # Compute BCELoss using fake images\n",
    "        # First term of the loss is always zero since fake_labels == 0\n",
    "        z = torch.randn(batch_size, latent_size)\n",
    "        z = Variable(z)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        # If D is trained so well, then don't update\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        reset_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        # ================================================================== #\n",
    "        #                        Train the generator                         #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # Compute loss with fake images\n",
    "        z = torch.randn(batch_size, latent_size)\n",
    "        z = Variable(z)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        \n",
    "        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
    "        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        # if G is trained so well, then don't update\n",
    "        reset_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        # =================================================================== #\n",
    "        #                          Update Statistics                          #\n",
    "        # =================================================================== #\n",
    "        d_losses[epoch] = d_losses[epoch]*(i/(i+1.)) + d_loss.data*(1./(i+1.))\n",
    "        g_losses[epoch] = g_losses[epoch]*(i/(i+1.)) + g_loss.data*(1./(i+1.))\n",
    "        real_scores[epoch] = real_scores[epoch]*(i/(i+1.)) + real_score.mean().data*(1./(i+1.))\n",
    "        fake_scores[epoch] = fake_scores[epoch]*(i/(i+1.)) + fake_score.mean().data*(1./(i+1.))\n",
    "        \n",
    "        if (i+1) % 200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch, num_epochs, i+1, total_step, d_loss.data, g_loss.data, \n",
    "                          real_score.mean().data, fake_score.mean().data))\n",
    "    \n",
    "    # Save real images\n",
    "    if (epoch+1) == 1:\n",
    "        images = images.view(images.size(0), 1, 28, 28)\n",
    "        save_image(denorm(images.data), os.path.join(sample_dir, 'real_images.png'))\n",
    "    \n",
    "    # Save sampled images\n",
    "    fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n",
    "    save_image(denorm(fake_images.data), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n",
    "    \n",
    "    # Save and plot Statistics\n",
    "    np.save(os.path.join(save_dir, 'd_losses.npy'), d_losses)\n",
    "    np.save(os.path.join(save_dir, 'g_losses.npy'), g_losses)\n",
    "    np.save(os.path.join(save_dir, 'fake_scores.npy'), fake_scores)\n",
    "    np.save(os.path.join(save_dir, 'real_scores.npy'), real_scores)\n",
    "    \n",
    "    plt.figure()\n",
    "    pylab.xlim(0, num_epochs + 1)\n",
    "    plt.plot(range(1, num_epochs + 1), d_losses, label='d loss')\n",
    "    plt.plot(range(1, num_epochs + 1), g_losses, label='g loss')    \n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'loss.pdf'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    pylab.xlim(0, num_epochs + 1)\n",
    "    pylab.ylim(0, 1)\n",
    "    plt.plot(range(1, num_epochs + 1), fake_scores, label='fake score')\n",
    "    plt.plot(range(1, num_epochs + 1), real_scores, label='real score')    \n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'accuracy.pdf'))\n",
    "    plt.close()\n",
    "\n",
    "    # Save model at checkpoints\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        torch.save(G.state_dict(), os.path.join(save_dir, 'G--{}.ckpt'.format(epoch+1)))\n",
    "        torch.save(D.state_dict(), os.path.join(save_dir, 'D--{}.ckpt'.format(epoch+1)))\n",
    "\n",
    "# Save the model checkpoints \n",
    "torch.save(G.state_dict(), 'G.ckpt')\n",
    "torch.save(D.state_dict(), 'D.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Candidate Papers/ Deep Learning Models Applicable to Art Generation Domain.\n",
    "\n",
    "\n",
    "1. Generative Adversarial Networks\n",
    "    - [Self Attention GAN](https://github.com/heykeetae/Self-Attention-GAN)\n",
    "    - [StyleGAN2](https://github.com/lucidrains/stylegan2-pytorch)\n",
    "2. [Denoising Diffusion Probabilistic models](https://github.com/lucidrains/denoising-diffusion-pytorch)\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
